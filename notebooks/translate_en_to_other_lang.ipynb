{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import pandas as pd\n",
    "import os, numpy as np\n",
    "from transformers import MarianMTModel, MarianTokenizer\n",
    "from time import time\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunks(lst, n):\n",
    "    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n",
    "    for i in range(0, len(lst), n):\n",
    "        yield lst[i:i + n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_file(sents, dump_fname):\n",
    "    with open(dump_fname,'w') as fh:\n",
    "        print(sents, file=fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_fname = 'data/sampled_for_trans.csv'\n",
    "sdf = pd.read_csv(ds_fname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert sdf.shape[0] == 24000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = list(sdf.comment_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(text) == 24000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************************************************************************\n",
      "processing translation to: es\n",
      "using tokenizer: <transformers.tokenization_marian.MarianTokenizer object at 0x7fb85eafae48> and \n",
      "model: Helsinki-NLP/opus-mt-en-es\n",
      "processing batch:  1\n",
      "Completed batch: 1 in 11.2 sec\n",
      "Translated so far: 30\n",
      "processing batch:  2\n",
      "Completed batch: 2 in 3.42 sec\n",
      "Translated so far: 40\n",
      "Translated all en sentences into es, using Helsinki-NLP/opus-mt-en-es in 15 sec\n",
      "Dumped all es sentences into: en-to-es.txt\n",
      "********************************************************************************\n",
      "********************************************************************************\n",
      "processing translation to: it\n",
      "using tokenizer: <transformers.tokenization_marian.MarianTokenizer object at 0x7fb85e358cf8> and \n",
      "model: Helsinki-NLP/opus-mt-en-it\n",
      "processing batch:  1\n",
      "Completed batch: 1 in 38.61 sec\n",
      "Translated so far: 30\n",
      "processing batch:  2\n",
      "Completed batch: 2 in 3.88 sec\n",
      "Translated so far: 40\n",
      "Translated all en sentences into it, using Helsinki-NLP/opus-mt-en-it in 42 sec\n",
      "Dumped all es sentences into: en-to-it.txt\n",
      "********************************************************************************\n"
     ]
    }
   ],
   "source": [
    "tgt_langs = ['es','it']\n",
    "for t in tgt_langs:\n",
    "    print('*'*80)\n",
    "    print(f'processing translation to: {t}')\n",
    "    trans_sents = []\n",
    "\n",
    "    model_name = 'Helsinki-NLP/opus-mt-en-'+t\n",
    "    tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "    model = MarianMTModel.from_pretrained(model_name)\n",
    "    model = model.cuda()\n",
    "    print(f'using tokenizer: {tokenizer} and \\nmodel: {model_name}')\n",
    "\n",
    "    epoch_t0 = time()\n",
    "    for batch_num, batch_text in enumerate(chunks(text[:40],BATCH_SIZE), start=1):\n",
    "        print('processing batch: ', batch_num)\n",
    "        t0 = time()\n",
    "        batch_text_inputs = tokenizer.prepare_translation_batch(batch_text, max_length=256)\n",
    "        batch_text_inputs = {k:v.cuda() for k,v in batch_text_inputs.items()}\n",
    "        translated = model.generate(**batch_text_inputs)\n",
    "        translated = [tokenizer.decode(t, skip_special_tokens=True) for t in translated]\n",
    "        trans_sents.extend(translated)\n",
    "        batch_time = time() - t0\n",
    "        print(f'Completed batch: {batch_num} in {round(batch_time,2)} sec')\n",
    "        print(f'Translated so far: {len(trans_sents)}')\n",
    "    full_tras_time = round(time()-epoch_t0)\n",
    "    print(f'Translated all en sentences into {t}, using {model_name} in {full_tras_time} sec')\n",
    "\n",
    "\n",
    "    dump_fname = f'en-to-{t}.txt'\n",
    "    save_to_file(trans_sents, dump_fname)\n",
    "    print(f'Dumped all es sentences into: {dump_fname}')\n",
    "    print('*'*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using tokenizer: <transformers.tokenization_marian.MarianTokenizer object at 0x7f3c0deecda0> and \n",
      "model: Helsinki-NLP/opus-mt-en-trk\n",
      "processing batch:  1\n",
      "Completed batch: 1 in 12.97 sec\n",
      "Translated so far: 30\n",
      "processing batch:  2\n",
      "Completed batch: 2 in 4.61 sec\n",
      "Translated so far: 40\n",
      "Translated all en sentences into turkish, using Helsinki-NLP/opus-mt-en-trk in 18 sec\n"
     ]
    }
   ],
   "source": [
    "trans_sents = []\n",
    "\n",
    "model_name = 'Helsinki-NLP/opus-mt-en-trk'\n",
    "tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "model = MarianMTModel.from_pretrained(model_name)\n",
    "model = model.cuda()\n",
    "print(f'using tokenizer: {tokenizer} and \\nmodel: {model_name}')\n",
    "\n",
    "epoch_t0 = time()\n",
    "for batch_num, batch_text in enumerate(chunks(text[:40],BATCH_SIZE), start=1):\n",
    "    print('processing batch: ', batch_num)\n",
    "    t0 = time()\n",
    "    batch_text_inputs = tokenizer.prepare_translation_batch(batch_text, max_length=256)\n",
    "    batch_text_inputs = {k:v.cuda() for k,v in batch_text_inputs.items()}\n",
    "    translated = model.generate(**batch_text_inputs)\n",
    "    translated = [tokenizer.decode(t, skip_special_tokens=True) for t in translated]\n",
    "    trans_sents.extend(translated)\n",
    "    batch_time = time() - t0\n",
    "    print(f'Completed batch: {batch_num} in {round(batch_time,2)} sec')\n",
    "    print(f'Translated so far: {len(trans_sents)}')\n",
    "full_tras_time = round(time()-epoch_t0)\n",
    "print(f'Translated all en sentences into turkish, using {model_name} in {full_tras_time} sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_ext = ['>>tur<< '+t for t in text]\n",
    "len(text_ext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using tokenizer: <transformers.tokenization_marian.MarianTokenizer object at 0x7f3c0ccf0ef0> and \n",
      "model: Helsinki-NLP/opus-mt-en-trk\n",
      "processing batch:  1\n",
      "Completed batch: 1 in 11.11 sec\n",
      "Translated so far: 30\n",
      "processing batch:  2\n",
      "Completed batch: 2 in 2.55 sec\n",
      "Translated so far: 40\n",
      "Translated all en sentences into turkish, using Helsinki-NLP/opus-mt-en-trk in 14 sec\n"
     ]
    }
   ],
   "source": [
    "trans_sents_ext = []\n",
    "\n",
    "model_name = 'Helsinki-NLP/opus-mt-en-trk'\n",
    "tokenizer = MarianTokenizer.from_pretrained(model_name)\n",
    "model = MarianMTModel.from_pretrained(model_name)\n",
    "model = model.cuda()\n",
    "print(f'using tokenizer: {tokenizer} and \\nmodel: {model_name}')\n",
    "\n",
    "epoch_t0 = time()\n",
    "for batch_num, batch_text in enumerate(chunks(text_ext[:40],BATCH_SIZE), start=1):\n",
    "    print('processing batch: ', batch_num)\n",
    "    t0 = time()\n",
    "    batch_text_inputs = tokenizer.prepare_translation_batch(batch_text, max_length=256)\n",
    "    batch_text_inputs = {k:v.cuda() for k,v in batch_text_inputs.items()}\n",
    "    translated = model.generate(**batch_text_inputs)\n",
    "    translated = [tokenizer.decode(t, skip_special_tokens=True) for t in translated]\n",
    "    trans_sents_ext.extend(translated)\n",
    "    batch_time = time() - t0\n",
    "    print(f'Completed batch: {batch_num} in {round(batch_time,2)} sec')\n",
    "    print(f'Translated so far: {len(trans_sents_ext)}')\n",
    "full_tras_time = round(time()-epoch_t0)\n",
    "print(f'Translated all en sentences into turkish, using {model_name} in {full_tras_time} sec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":Dear god this site is horrible.\n",
      "--------------------------------------------------------------------------------\n",
      "; watin bu sayt çox yaramaz.\n",
      "--------------------------------------------------------------------------------\n",
      "\"Sevgili tanrım, bu site korkunç.\n",
      "--------------------------------------------------------------------------------\n",
      "********************************************************************************\n",
      "********************************************************************************\n",
      "\n",
      "\"*::::::::I believe that you're confusing \"\"precision\"\" with \"\"accuracy\"\". I'm using the word precison in its mathematical sense, the number of digits following the decimal place in this case.   \n",
      "\"\n",
      "--------------------------------------------------------------------------------\n",
      "*:: \"Эмне: \"Эгер \"спедика\" диагнозлық\", \"babby\" сөзі математикалық olarak, рационалда жататын дистогнозлық сандардың саны.\n",
      "--------------------------------------------------------------------------------\n",
      "\"*::: \"Ben inanıyorum ki \"preciation\" ile kafanı karıştırmışsın. Bu davadaki ortak noktadan sonraki sihirbazlık\" derken, \"Preciation\" kelimesini kullanıyorum.\n",
      "--------------------------------------------------------------------------------\n",
      "********************************************************************************\n",
      "********************************************************************************\n",
      "\n",
      "bbq \n",
      "\n",
      "be a man and lets discuss it-maybe over the phone?\n",
      "--------------------------------------------------------------------------------\n",
      "bbq ҫын пулнӑ пулсан, ӑна telefon умӗнче сӳтсе явма юрать - и?\n",
      "--------------------------------------------------------------------------------\n",
      "Bbq bir erkek olabilir ve telefonda konuşabilir miyiz?\n",
      "--------------------------------------------------------------------------------\n",
      "********************************************************************************\n",
      "********************************************************************************\n",
      "\n",
      "Before you start throwing accusations and warnings at me, lets review the edit itself-making ad hominem attacks isn't going to strengthen your argument, it will merely make it look like you are abusing your power as an admin. \n",
      "Now, the edit itself is relevant-this is probably the single most talked about event int he news as of late. His absence is notable, since he is the only living ex-president who did not attend. That's certainly more notable than his dedicating an aircracft carrier. \n",
      "I intend to revert this edit, in hopes of attracting the attention of an admin that is willing to look at the issue itself, and not throw accusations around quite so liberally. Perhaps, if you achieve a level of civility where you can do this, we can have a rational discussion on the topic and resolve the matter peacefully.\n",
      "--------------------------------------------------------------------------------\n",
      "Suçulara we ескертуlara atmazdan öň, редакциялауды başlamazdan öň, редакциялау möwritial шағирлауыңызның күшін арттыра алмайды. Депрессияның үстебен тәріздістей көрінеді. Қазір, өңдеу - унӑн алыскы мәлімалы халықтарында ол тек өнер көрсеткен, себебі ол жарлықтан көптеген позиден кедергілі, өйткені унӑн позициясына жарнама алынады. Өзінің жарнамалары - конфутбустығына және конфликтивтік мәлімдеге назар аударып тұрады. Көпшілікке мен сизгерлердің артығында конфекторлаймын. Эскерлердің алдында өнеральтерациялық жағдайына оралдан артық қарай, ola-қай аласыз. Жарqiqчылык пен хобрманы özüne тартасыз.\n",
      "--------------------------------------------------------------------------------\n",
      "Bana suçlamaları ve uyarıları atmadan önce, düzenleme saldırılarını incelemenize izin vereceksiniz, kendinize hümmin saldırıları güçlendiremeyeceğiniz gibi göstereceksiniz. Şimdi, bu da senin gücünü işgal ettiğiniz gibi gösterecektir.\n",
      "--------------------------------------------------------------------------------\n",
      "********************************************************************************\n",
      "********************************************************************************\n",
      "\n",
      "Bye! \n",
      "\n",
      "Don't look, come or think of comming back! Tosser.\n",
      "--------------------------------------------------------------------------------\n",
      "Білме, кел! Tosser geri transfer деп ойлаma.\n",
      "--------------------------------------------------------------------------------\n",
      "Bakmayın, geri dönmeyi düşünün.\n",
      "--------------------------------------------------------------------------------\n",
      "********************************************************************************\n",
      "********************************************************************************\n",
      "\n",
      "@RedSlash, cut it short. If you have sources stating the RoK is sovereign post them. Otherwise please aknowledge WP is not the place to make OR.\n",
      "--------------------------------------------------------------------------------\n",
      "ҚызылSlash, gysga пункт. Егерӳр үздік құқықтарыңыз болса, құпияларыңыз RoK-дің Әкрение hökmdarы дейді. Әйтпесе, білім алу үшін SABBET ET емес.\n",
      "--------------------------------------------------------------------------------\n",
      "Kırmızı Slash, kısa kesin.\n",
      "--------------------------------------------------------------------------------\n",
      "********************************************************************************\n",
      "********************************************************************************\n",
      "\n",
      "REDIRECT Talk:Mi Vida Eres Tú\n",
      "--------------------------------------------------------------------------------\n",
      "DEDIRECT: Mini Eda Eres Tusu\n",
      "--------------------------------------------------------------------------------\n",
      "Vida Eres Tusu\n",
      "--------------------------------------------------------------------------------\n",
      "********************************************************************************\n",
      "********************************************************************************\n",
      "\n",
      "\" \n",
      " :There are now four references, including Britannica, giving the correct date, which is getting silly. You complain in your edit summary that you can't find them, so I've added quotes to two, to help you out. After that you're on your own: WP:SOURCEACCESS has more on this. I'm happy to concede that Britannica, alone, mentions the date you offer (but without explaining the context), so that's one of the sources I've expanded with a quote specifically mentioning 23 August.  \n",
      "\n",
      " :Russian Wikipedia has: \"\"23 августа силы 14-го танкового корпуса армии Паулюса вышли к Волге севернее Сталинграда\"\"  (\"\"August 23 forces of the 14th Tank Corps, Army [of] Paulus, reached the Volga north of Stalingrad\"\"), cited from the war diary of Colonel-General Franz Haider.  \n",
      "\n",
      " :  \"\n",
      "--------------------------------------------------------------------------------\n",
      ": Хәҙер анда dört дәлил бар, шул иҫәптән күңсіздік пайдалы дата бар. Репинисіңізде siz оларды таба алмайсыз. Сюзанга екі терминдарды қоса салдыңыз. W: WPURACES. содан кейін, сіздер өз алдын-сайтына тек siziň бер мәлімдемелеріңіздің растамасы бар (\"Pequmeraeansia of August Books of the Tubegrape, August Books apain: August compain of Manbas As festies».Çüncki: “Angomous Apekia bigory is apanikalia bigory of the keyword between brackets (e. g. ServerName, ServerAdmin, etc.)\n",
      "--------------------------------------------------------------------------------\n",
      "Şu anda dört referans var, alçakgının da dahil. Siz onları bulmanız için iki röntgen eklediğinizden şikâyet ediyorsunuz.\n",
      "--------------------------------------------------------------------------------\n",
      "********************************************************************************\n",
      "********************************************************************************\n",
      "\n",
      "I don't believe the Lisak criticism present there conforms with the NPV rule.  Lisak doesn't have a neutral point of view to begin with.  If an offer to polygraph or even concerned review of polygraph results shocks a complainant into thinking her lies have been uncovered, the recantation is still perfectly valid.  If you know you are telling the truth, you will argue with machine or investigator.  Also part of Kanin's research was a followup of the recanted story where possible to verify if any were false recantations.  In all followups the recanted version of events matched what the accused said happened.\n",
      "\n",
      "Arguing that Lisak is a respected PHD is baseless if Kanin is a respected PHD.  I agree that my edit wasn't as neutral as possible though, so apologize for that.  Still something must be done here.\n",
      "--------------------------------------------------------------------------------\n",
      "Мен LisaHK-ның NPV ережелерімен ризалашпаймын. Лизаның көз караштағы сығым-мананистралық позициясы жоқ. Егер бір поплагия ұсынса немесе поплагия пайда болғанын сынса, яғни, поплагияны зерттеп алғанда, күтүлбөгөн жерден реакция пайда болады. Егергерлеріңіздің чындык-зерттесеңіз, яғни, провайдер тал астындағы техникалық шеңберлермен талқылаймын. Сонымен қатар, эгердебек конфигурацияланғаннан соң, конфиденциентке қараса-тация қабылданғаннан соң, анда мен Kastruk PHKPHP.AD конфицестивіненциясын қабылдап, эгер бәліп алып тасталсам, бұданғанды.\n",
      "--------------------------------------------------------------------------------\n",
      "Lisak eleştirisinin NPV kuralları ile aynı fikirde olduğuna inanmıyorum. Lisak'ın başlangıçtan başlamak için lastik bir durumu olmadığına inanmıyorum. Eğer popograg sonuçları yorumlanıyorsa ya da onun yalan olduğunu düşündüğünde şikayet şokları gözden geçiren bir şikâyet şok edicidir. Eğer bilirseniz, doğruyu söylediğiniz doğruyu söyleyin. Yanıltılı araştırmacılar, ya da mücadeleciliğin gerçekleşen bir parçasıdır.\n",
      "--------------------------------------------------------------------------------\n",
      "********************************************************************************\n",
      "********************************************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\" \n",
      " :That is ridiculous. Unless there's a good and non-disingenuous response, I would absolutely agree with you blocking indef outright. Falsifying sources should simply never be tolerated. //  \"\n",
      "--------------------------------------------------------------------------------\n",
      "\"Kesinlikle, bu saçma, ya da nädogru жауап bolmasa, men sizi acil kabul ederdim. Galiba sertifika etmek hiç haçan kabul edilmez. / \"/\"\n",
      "--------------------------------------------------------------------------------\n",
      "\"Güzel, bu saçma bir tepkisi yoksa, seni açıkça engellemenizle kesinlikle aynı fikirde olurum. Galsing kaynakların hiçbir zaman kabul edilmemesi gerekmez. / \"\n",
      "--------------------------------------------------------------------------------\n",
      "********************************************************************************\n",
      "********************************************************************************\n",
      "\n",
      "How dare you vandalize that page about the HMS Beagle! Don't vandalize again, demon!\n",
      "--------------------------------------------------------------------------------\n",
      "HMS Beagle жөнүндөгү şol sahypa nähili гана кивел!\n",
      "--------------------------------------------------------------------------------\n",
      "HMS Beagle hakkındaki sayfayı nasıl gerginleştiriyorsun?\n",
      "--------------------------------------------------------------------------------\n",
      "********************************************************************************\n",
      "********************************************************************************\n",
      "\n",
      "Are you threatening me for disputing neutrality? I know in your country it's quite common to bully your way through a discussion and push outcomes you want. But this is not Russia.\n",
      "--------------------------------------------------------------------------------\n",
      "Memleketinizdə siz meni bitarap hünär Möhkünledýärsiňizmi? Bileмін, bu genelçilik договор арқылы sahnalaşdyrылады. Ama bu Rusya deyil.\n",
      "--------------------------------------------------------------------------------\n",
      "Ülkenizde tartışma için beni tehdit ediyor musunuz?\n",
      "--------------------------------------------------------------------------------\n",
      "********************************************************************************\n",
      "********************************************************************************\n",
      "\n",
      "Thanks! Undeletion was more than I'd hoped for. I'm researching the status of Texas government (including local government) copyright status, but it's slow going. Apparently works of the Florida government are usually public domain, but we don't have a similar article on Texas, so I guess I'll have to research the old-fashioned, non-lazy, actually reliable way. Or ask the copyright help desk, like you suggested. In the meantime, I'm using the fair use rationale, since it's valid while the image is used in an article. Thanks again! -\n",
      "--------------------------------------------------------------------------------\n",
      "Minnett/Lütfenim! Мен Texas үкімет абалын, сондай-ақ yerel правительгия республикасы (католик правительстовия республикасы) жұмысын тикшерәмін, бірақ ол баяу. Күрәсең, Флорида хөкүмәттің жұмыстары әдетте халӑх әлемдік домен, бірақ бізде дә оның охшаш ядғында Техас штатында жоқ дейм, сондықтан мен ескі-лизагола платформалар үшін көмек ұсынамын.\n",
      "--------------------------------------------------------------------------------\n",
      "Tahliye'nin resepsiyonunu araştırıyorum. Ben Texas hükümetinin (ölgesel hükümet de dahil) statüsünü araştırıyorum, ama genellikle de Florida hükümetinin çalışmaları yavaşdır. Görünüşe göre, o zaman eski Teksas'a benzer bir makale yok.\n",
      "--------------------------------------------------------------------------------\n",
      "********************************************************************************\n",
      "********************************************************************************\n",
      "\n",
      "\" \n",
      "\n",
      " == Cloud feedback == \n",
      "\n",
      " Why is cloud feedback only under the positive feedbacks? Just about any paper states that it can be both. That the IPCC states that it is \"\"more likely a positive than a negative feedback\"\" doesn't change that.   \"\n",
      "--------------------------------------------------------------------------------\n",
      "== \"Buутбуклюдж == 'баңы бұл оң кеңістік орбиталар' деген сөздер астындағы һәр kağızда да болады.bil газ тулыһында, бұл \". kağız\". IPC жүйесінде бұл \"техникалық жағдай\" емес сипаттамауы мүмкін.\n",
      "--------------------------------------------------------------------------------\n",
      "Bu Bulut geri dönüşümü neden sadece pozitif ifadeler altındadır?\n",
      "--------------------------------------------------------------------------------\n",
      "********************************************************************************\n",
      "********************************************************************************\n",
      "\n",
      "== Second issue == \n",
      "\n",
      " I'm thinking we need a taxonomy section; there are things that aren't really as clear as they maybe could be. Why is/what specific findings about the fossils places R. narmadensis in the subfamily Carnotaurinae? Why 'princely lizard of the Narmada'; is that significant as to the stature/behavior/predatorial prowess of R. narmadensis? If there is anything more precise on its taxonomy, such as that, it would be great to add.\n",
      "--------------------------------------------------------------------------------\n",
      "== Ikinjiden, менің pikiriмçe, bize salgyt tiresi gerek. Бәлкім, onlar мүмкін, мынандай zatlara жүйөлүү қажет. Niçin R. narnotinsanisos katoliklerinde munuň näme üçin olduğunu biliyorsunuz? Niçin - 'pen Armania Carntina krantina'nın bolegesi; näme üçin? Narmaigen/Ridenke/Romernokerhyera kuvveti, genel/Romermaies=/Romermaighnuthnutil=/Romerkey=-datactracture(tandarghy vergi). Do not translate the keyword between brackets (e. g. ServerName, ServerAdmin, etc.)\n",
      "--------------------------------------------------------------------------------\n",
      "== İkinci soru == Düşünüyorum ki vergi bölümüne ihtiyacımız var, belki de olabileceği kadar açık değildir. Neden bu fosiller R. Narmanitis'in devanesi'nin devasa kıyafetleri, niçin Narma'nın denizaltı kısımları gibi önemli bir şeydir.\n",
      "--------------------------------------------------------------------------------\n",
      "********************************************************************************\n",
      "********************************************************************************\n",
      "\n",
      "That's what I'm looking through, it looks like he was just being an all around dick on talk pages though. It's nothing too bad though, looks more like an inability to express himself properly. Thank you for your concern also, Cheers!! -\n",
      "--------------------------------------------------------------------------------\n",
      "Bu hamala sikime baktığım o, adi bütün sik беттерде adi, бірақ adi adi, ahbap. бұл ғалам, zehinsiz, ahbap!\n",
      "--------------------------------------------------------------------------------\n",
      "Ben de öyle bakıyorum, sadece konuşma sayfalarında her yerde sik gibi görünüyordu ama çok kötü bir şey değil, kendisini doğru düzgün ifade edemeyeceğin bir şey gibi görünüyor.\n",
      "--------------------------------------------------------------------------------\n",
      "********************************************************************************\n",
      "********************************************************************************\n",
      "\n",
      "\"\n",
      "\n",
      "Christ. \"\"IQ is selected for therefore every population has the same IQ.\"\" Never ceases to amaze me.   \n",
      "\n",
      "\"\n",
      "--------------------------------------------------------------------------------\n",
      "\"IQ\" her калье үшін сайланған, сондықтан барлық кальма IQ\" ның гражданы арқасында. Жубайым таң кала бермей қалды.\n",
      "--------------------------------------------------------------------------------\n",
      "Bu nedenle her nüfusun imparatorlukla aynı imparatorluğu vardır. Beni şaşırtmaktan asla vazgeçmez.\n",
      "--------------------------------------------------------------------------------\n",
      "********************************************************************************\n",
      "********************************************************************************\n",
      "\n",
      "Website \n",
      "\n",
      "Hey all,\n",
      "I was thinking of getting myself a website to display my pictures and this was the cheapest thing I could find. I don't know about others, but Fir and Diliff, you guys have websites, do you think it is legit? Could you provide any better alternatives? Help from any other guild member is also appreciated. Thanks (talk)\n",
      "--------------------------------------------------------------------------------\n",
      "Сайтта, веб - сайтымды көрсеткім келмесе, мен özüme веб-сайт сатып ала алам деп ойладым.\n",
      "--------------------------------------------------------------------------------\n",
      "Selam, kendime resimlerimi göstermek için bir web site almayı düşünüyordum ve bu bulabileceğim en ucuz şeydi.\n",
      "--------------------------------------------------------------------------------\n",
      "********************************************************************************\n",
      "********************************************************************************\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Transliteration of Russian place names\n",
      "In writing about Moscow Metro for the Malayalam Wikipedia, we are finding it difficult to correctly transliterate the Russian place names. For example, do we pronounce Park Kultury as PAARK KALTTARI or PAARK KALCHCHARI (or perhaps something completely different)? Can somebody please help by transliterating the list given in https://ml.wikipedia.org/wiki/സംവാദം:മോസ്കോ_മെട്രോ. (I am not putting the list here as I don't want to clutter up this page.) Thanks\n",
      "--------------------------------------------------------------------------------\n",
      "Мәскәү Malayalam Wikipedia үшін rus урыннарының исемдерін жаза бастап, Biz Мәскәү Метроның исемен дөрөҫ литерациялау җиңел түгел. Мысалы, Park Kulty KARKETI немесе ПARKALI (яғни ВОСИКИ) литеребіне (яның қандай да булһа бір түрлерге) yardım бере алады. Иде-бин лимония (1.org.org. com/wikimo_BAR_ wikim/IKDEBHI) Бұл rshown. Лиценттттердің тізімінің исемдерін алып тастап, алардан пайда алуына шамамыз.\n",
      "--------------------------------------------------------------------------------\n",
      "Malayalam Wikipedia için Moskova Metro isimlerini yazan Rusya'nın ismini doğru şekilde Rusya'nın isimlerini yazmakta zorunlu bulunuyoruz. Örneğin, PAKARKTARKARKARI veya PARKAKIKIKI (YAKIKI) veya başka bir şeye yardımcı olabiliriz.\n",
      "--------------------------------------------------------------------------------\n",
      "********************************************************************************\n",
      "********************************************************************************\n",
      "\n",
      "I find it amusing that I am accused of using multiple accounts when the only account I have is this one, however I am used to false charges being brought against be by B&Q.;\n",
      "It has become apparent to me that wikipedia is not interested in a truth but more in advertising revenue.\n",
      "--------------------------------------------------------------------------------\n",
      "Meni ancaq bu тіркелгі olduğum zaman, бірнеше hesabatlar куллануда гаепләү кызыктырады. Ýöne meni BTOQ tarafından жала-тандырылган aýyplamaларга javoblaýarlar; reklampa etmek bihaberia емес, gaýtam, reklambasında Kiwidia olduğunu дааналады.\n",
      "--------------------------------------------------------------------------------\n",
      "Ben sadece bu hesabı kullandığımda birçok hesap kullanmakla suçlanıyorum, ama BTOQ tarafından suçlanmakta olduğum yanlış suçlamalar kullanılmaktadır. Bu bana reklamın gerçekle ilgilenmediğini gösteriyor.\n",
      "--------------------------------------------------------------------------------\n",
      "********************************************************************************\n",
      "********************************************************************************\n",
      "\n",
      "MY OWN PAGE HOWEVER I LIKE IT\n",
      "--------------------------------------------------------------------------------\n",
      "Olaryň köpüsi känbir geplemediler.\n",
      "--------------------------------------------------------------------------------\n",
      "SAYFA SAYFA\n",
      "--------------------------------------------------------------------------------\n",
      "********************************************************************************\n",
      "********************************************************************************\n",
      "\n",
      ":::While I tend to agree with all of this and am as slightly annoyed as anyone that we appear to have been blamed even though our article was accurate and respectful at all times, and Mr. Roth was treated with dignity and respect at all times... it's always in my nature to think about how we might do better in the future.\n",
      "--------------------------------------------------------------------------------\n",
      ": \"Benim Bunlar bilen ylalaşсам,.....\"Her zaman anyk, sylaşyksyz мөгамәлә edilse --\"Mercil Roth,...\"Mənim aslynda, gelejekde nämeler etjekdigimiz barada oýlanyp көр................................................\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"\"...\n",
      "--------------------------------------------------------------------------------\n",
      "Mr.: Bütün bunlarla katılmaya eğilimliyken ve makalemiz her zaman doğru ve saygı gösterilmesine rağmen suçlandığımız herkes gibi biraz sinirlenmeye başlasam da Bay Roth, her zaman nezakete ve saygına saygı gösterildiyse de benim doğamda ne kadar daha iyi olacağını düşünmem gerekir.\n",
      "--------------------------------------------------------------------------------\n",
      "********************************************************************************\n",
      "********************************************************************************\n",
      "\n",
      ":::also fwiw I nominated polyamorous people for deleting, take a look and weigh in if you like.\n",
      "--------------------------------------------------------------------------------\n",
      "Пирӗн, бала чагыбызда мал - мөлкәт җыю зарури.\n",
      "--------------------------------------------------------------------------------\n",
      ": \"Ben de silmek için kıyafetli bir insan değilim, isterseniz bakın ve ağırlıklı olun.\n",
      "--------------------------------------------------------------------------------\n",
      "********************************************************************************\n",
      "********************************************************************************\n"
     ]
    }
   ],
   "source": [
    "for eng,trk,tur in zip(text, trans_sents, trans_sents_ext):\n",
    "    print(eng)\n",
    "    print('-'*80)\n",
    "    print(trk)\n",
    "    print('-'*80)\n",
    "    print(tur)\n",
    "    print('-'*80)\n",
    "    print('*'*80)\n",
    "    print('*'*80)\n",
    "    input()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
